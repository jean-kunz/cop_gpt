{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sEwaNBgEHox"
   },
   "source": [
    "# minGRU and minLSTM\n",
    "\n",
    "https://arxiv.org/pdf/2410.01201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54RVFWN_VWco"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbHYf5wCEc7M"
   },
   "source": [
    "## Parallel scan\n",
    "\n",
    "https://arxiv.org/html/2311.06281v4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkhBuWAH-ykm"
   },
   "source": [
    "Sample code for computing the sequence\n",
    "\n",
    "$$x_t=a_t x_{t-1} + b_t$$\n",
    "\n",
    "efficiently in parallel, given\n",
    "$t=(1,2,…,n), a_t∈R^n, b_t∈R^n$ , and initial value\n",
    "$x_0 ∈ R$.\n",
    "\n",
    "See \"Efficient Parallelization of a Ubiquitious Sequential Computation\" (Heinsen, 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9ulHvK39Rah"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from icecream import ic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkUObui3BczX"
   },
   "source": [
    "## naive sequential implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkWLX8Ab9as5"
   },
   "outputs": [],
   "source": [
    "def naively_compute_sequentially(coeffs, values):\n",
    "    x = [values[0]]  # x_0\n",
    "    ic(x)\n",
    "\n",
    "    for a, b in zip(coeffs, values[1:]):\n",
    "        x.append(a * x[-1] + b)\n",
    "        ic(x, x[-1], a, b)\n",
    "\n",
    "    return torch.stack(x)\n",
    "\n",
    "\n",
    "device = \"mps\"  # change as necessary\n",
    "seq_len = 5  # _000_000  # change as you wish\n",
    "\n",
    "# Generate some random input data:\n",
    "coeffs = torch.randn(seq_len, device=device)\n",
    "values = torch.randn(1 + seq_len, device=device)  # includes initial value\n",
    "ic(coeffs, values)\n",
    "# Compute the sequence:\n",
    "x = naively_compute_sequentially(coeffs, values)  # includes initial value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9z-E3BXBiSQ"
   },
   "source": [
    "## Parallel implementation\n",
    "\n",
    "\n",
    "$$\\log x_t = a_t^* + \\log(x_0 + b_t^*) \\tag{1}$$\n",
    "\n",
    "where $a_t^*$ and $b_t^*$ are the 2 prefix (cumulative) sums:\n",
    "\n",
    "$$a_t^*=\\sum_{t}^{cum} \\log a_t \\tag{2} $$\n",
    "\n",
    "$$b_t^*=\\sum_{t}^{cum} e^{\\log b_t-a_t^*} \\tag{3} $$\n",
    "\n",
    "Then we obtain $x_t$ with elementwise exponentiations\n",
    "\n",
    "$$x_t=e^{a_t^*+\\log(x_0 + b_t^*)} \\tag{4}$$\n",
    "\n",
    "It execute the same computations in parallel -- or more precisely, as a composition of two prefix sums, each of which is executable in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDT-8xttB83f"
   },
   "source": [
    "### General Case: If Any Input Can Be Negative\n",
    "If any inputs are negative, their logarithms are complex numbers:\n",
    "$$\\ln(x)=\\ln(\\lvert x \\lvert)+i\\pi$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCgoQbnnErBH"
   },
   "outputs": [],
   "source": [
    "def complex_log_impl(float_input, eps=1e-6):\n",
    "    eps = float_input.new_tensor(eps)\n",
    "    real = float_input.abs().maximum(eps).log()\n",
    "    imag = (float_input < 0).to(float_input.dtype) * torch.pi\n",
    "    return torch.complex(real, imag)\n",
    "\n",
    "\n",
    "complex_log_impl(torch.tensor(-2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHG_u4vk7BpS"
   },
   "outputs": [],
   "source": [
    "def complex_log(float_input: torch.Tensor):\n",
    "    # using torch native implem.\n",
    "    return torch.log(float_input.to(dtype=torch.complex64))\n",
    "\n",
    "\n",
    "cl = complex_log(torch.tensor(-2.0))\n",
    "cl, cl.real, cl.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BO5egJZr99QN"
   },
   "outputs": [],
   "source": [
    "def parallel_scan_log_(log_coeffs, log_values):\n",
    "    # log_coeffs: (batch_size, seq_len, input_size)\n",
    "    # log_values: (batch_size, seq_len + 1, input_size)\n",
    "    a_star = F.pad(torch.cumsum(log_coeffs, dim=1), (0, 0, 1, 0))\n",
    "    log_h0_plus_b_star = torch.logcumsumexp(log_values - a_star, dim=1)\n",
    "    log_h = a_star + log_h0_plus_b_star\n",
    "    torch.exp(log_h)[:, 1:]\n",
    "\n",
    "\n",
    "def parallel_scan_log(a, b):\n",
    "    # log_coeffs: (batch_size, seq_len, input_size)\n",
    "    # log_values: (batch_size, seq_len + 1, input_size)\n",
    "    a_b, a_s, a_h = a.shape\n",
    "    b_b, b_s, b_h = b.shape\n",
    "    assert a_b == b_b and a_h == b_h and a_s + 1 == b_s\n",
    "\n",
    "    log_a = complex_log(a)\n",
    "    ic(log_a.shape)\n",
    "    log_b = complex_log(b)\n",
    "    ic(log_b.shape)\n",
    "\n",
    "    # Split into real and imaginary parts\n",
    "    log_a_real, log_a_imag = log_a.real, log_a.imag\n",
    "    log_b_real, log_b_imag = log_b.real, log_b.imag\n",
    "\n",
    "    # Compute cumsum separately for real/imag parts\n",
    "    # Add padding row of zeros at start\n",
    "    a_star_real = F.pad(torch.cumsum(log_a_real, dim=1), (0, 0, 1, 0))\n",
    "    a_star_imag = F.pad(torch.cumsum(log_a_imag, dim=1), (0, 0, 1, 0))\n",
    "\n",
    "    # Recombine into complex\n",
    "    a_star = torch.complex(a_star_real, a_star_imag)\n",
    "    shifted = log_b_real - a_star\n",
    "    # adds one row of zeros at the beginning (top) of the tensor resulting from the cumulative sum.\n",
    "    # so shapes of a and b are aligned\n",
    "    # a_star = F.pad(torch.cumsum(log_a, dim=1), (0, 0, 1, 0))  # eq (2)\n",
    "    ic(a_star.shape)\n",
    "    assert a_star[0, 0, 0] == 0.0, \"There must be a row of 0. added\"\n",
    "\n",
    "    log_h0_plus_b_star = torch.logcumsumexp(shifted, dim=1)  # eq (1)\n",
    "    log_h = a_star + log_h0_plus_b_star  # eq (1)\n",
    "    h = torch.exp(log_h)[:, 1:].real  # eq(4)\n",
    "    return h\n",
    "\n",
    "\n",
    "ic.enable()\n",
    "device = \"mps\"  # change as necessary\n",
    "seq_len = 5  # 10_000_000  # change as you wish\n",
    "\n",
    "# take 0.1 of prev value and add it to current value\n",
    "coeffs = torch.tensor([[0.1, 0.1, 0.1, 0.1, 0.1]]).to(device).unsqueeze(-1)\n",
    "values = torch.tensor([[0.0, -1.0, -2.0, -3.0, -4.0, -5.0]]).to(device).unsqueeze(-1)\n",
    "\n",
    "# Compute the sequence:\n",
    "x = parallel_scan_log(coeffs, values)\n",
    "ic(x)\n",
    "assert x.shape == coeffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXjz5OyEoaw"
   },
   "source": [
    "## minGRU on shaekspeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nl1qEkXdTz8V"
   },
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-PpbPLSXuv8"
   },
   "outputs": [],
   "source": [
    "start_val = int(np.ceil(len(text) * 0.8))\n",
    "train_text = text[:start_val]\n",
    "val_text = text[start_val:]\n",
    "train_text[-10:], val_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scE60DqaWZuc"
   },
   "outputs": [],
   "source": [
    "class ShakespeareDataSet(Dataset):\n",
    "    def __init__(self, text: str, seq_len: int = 10):\n",
    "        self.text = text\n",
    "        self.chars = sorted(set(text))\n",
    "        self.char2idx = {c: i for i, c in enumerate(self.chars)}\n",
    "        self.idx2char = {i: c for i, c in enumerate(self.chars)}\n",
    "        self.data = [self.char2idx[c] for c in text]\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = self.data[idx : idx + self.seq_len]\n",
    "        y = self.data[idx + 1 : idx + self.seq_len + 1]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "ds = ShakespeareDataSet(text, seq_len=20)\n",
    "\n",
    "x, y = next(iter(ds))\n",
    "ic(x, y)\n",
    "\n",
    "batch_size = 256\n",
    "m = len(text) / batch_size\n",
    "dl = DataLoader(ds, batch_size=batch_size)\n",
    "\n",
    "x, y = next(iter(dl))\n",
    "ic(x.shape, y.shape)\n",
    "\n",
    "for i, (x, y) in enumerate(dl):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "speqqviDW_Vr"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAmeI0kfEkfY"
   },
   "source": [
    "The continuous function g ensures that $\\widetilde{h}_t ← g(Linear_{d_h}(xt))$ is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f20vdx3BhDG"
   },
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return torch.where(x >= 0, x + 0.5, torch.sigmoid(x))\n",
    "\n",
    "\n",
    "def log_g(x):\n",
    "    return torch.where(x >= 0, (F.relu(x) + 0.5).log(), -F.softplus(-x))\n",
    "\n",
    "\n",
    "sx = torch.tensor([[0.0, -0.2, 0.3], [0.8, -0.9, 1.5]])\n",
    "g_x = g(sx)\n",
    "log_g_x = log_g(sx)\n",
    "ic(sx, g_x, log_g_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RNsh-VnafAn"
   },
   "outputs": [],
   "source": [
    "class ShakespeareMinGRU(nn.Module):\n",
    "    def __init__(self, vocab_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.linear_z = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, h_0: torch.Tensor):\n",
    "        b, s = x_t.shape\n",
    "        assert h_0.shape == (b, 1, self.hidden_size)\n",
    "        # x_t = x_t.unsqueeze(-1)\n",
    "        x_emb = self.embeddings(x_t)\n",
    "        ic(x.shape, x_emb.shape, h_0.shape)\n",
    "        k = self.linear_z(x_emb)\n",
    "        ic(k.shape)\n",
    "        log_z = -F.softplus(-k)\n",
    "        ic(log_z.shape)\n",
    "        log_coeffs = -F.softplus(k)\n",
    "        log_h_0 = log_g(h_0)\n",
    "        log_tilde_h = log_g(self.linear_h(x_emb))\n",
    "        ic(log_coeffs.shape, log_h_0.shape, log_z.shape, log_tilde_h.shape)\n",
    "        cat = torch.cat([log_h_0, log_z + log_tilde_h], dim=1)\n",
    "        ic(cat.shape)\n",
    "        h = parallel_scan_log(log_coeffs, cat)\n",
    "        logits = self.fc(h)\n",
    "        return logits, h\n",
    "\n",
    "    def init_hidden(self, batch_size: int):\n",
    "        return torch.zeros((batch_size, 1, self.hidden_size))\n",
    "\n",
    "\n",
    "ic.enable()\n",
    "ic.disable()\n",
    "ic.configureOutput(includeContext=True, contextAbsPath=False)\n",
    "batch_size = 8\n",
    "dl = DataLoader(ds, batch_size=batch_size)\n",
    "x, y = next(iter(dl))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "model = ShakespeareMinGRU(vocab_size=ds.vocab_size, hidden_size=12).to(device)\n",
    "h0 = model.init_hidden(batch_size=batch_size).to(device)\n",
    "logits, h = model(x, h0)\n",
    "ic(h.shape);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hduLTtFafLo"
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "hidden_size = 256\n",
    "num_layers = 1  # Using single layer as in the paper's minGRU/minLSTM\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "learning_rate = 0.002\n",
    "\n",
    "model = ShakespeareMinGRU(vocab_size=ds.vocab_size, hidden_size=32).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWJ6Lq40aBmF"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_ds = ShakespeareDataSet(train_text, seq_len=seq_length)\n",
    "val_ds = ShakespeareDataSet(val_text, seq_len=seq_len)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        bs, sl = inputs.shape\n",
    "        h0 = model.init_hidden(bs).to(device)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        logits, h = model(inputs, h0)\n",
    "        logits = logits.reshape(-1, ds.vocab_size)\n",
    "        targets = targets.reshape(-1)\n",
    "        ic(logits.shape, targets.shape)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dl)}], Loss: {loss.item():.4f}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBINTgP1XAlx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMppLdA/ZraXknO5wIEKjhC",
   "gpuType": "T4",
   "mount_file_id": "12XtzQ8EOxJXhlb8OMMIgBfBc3lifE3PT",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cop-gpt-XeiTM7fR-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
