{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mingpt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_download:bool=False\n",
    "if do_download:\n",
    "    !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "len(text), text[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for i,s in enumerate(chars)}\n",
    "\n",
    "def encode(s: str) -> list[int]:\n",
    "    return [ stoi[c] for c in s]\n",
    "\n",
    "def decode(l: list[int]) -> str:\n",
    "    return \"\".join([ itos[i] for i in l])\n",
    "\n",
    "decode(encode(\"hello world\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor()\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data[:100]\n",
    "n = int(0.9*len(text))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "x,y\n",
    "for t in range(block_size):\n",
    "    ctx = x[:t+1]\n",
    "    tgt = y[t]\n",
    "    #print(t, ctx, tgt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split: str):\n",
    "    \n",
    "    data = train if split=='train' else val\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "    print(ix)\n",
    "    # ix are random starting points of each batch\n",
    "    x = torch.stack([data[i:i+block_size]for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "\n",
    "print(x)\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        ctx = xb[b,0:t+1]\n",
    "        tgt = yb[b,t]\n",
    "        #print(ctx,\"->\", tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(vocab_size,vocab_size)\n",
    "emb(torch.tensor([4,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.weight[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export(\"mingpt.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop_gpt",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
